{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('final_restaurant_review_data.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Actually ordered online with Deliveroo! disapp...\n",
       "1         Hate to write bad reviews but.... Bad service,...\n",
       "2         Tempting pizzas I went with a couple a family ...\n",
       "3         Quick lunch pizza Great pizza. Easy to order a...\n",
       "4         Nice italian thin crust pizzas Good for casual...\n",
       "                                ...                        \n",
       "400936    Poor service and food is below average. Wanted...\n",
       "400937    Questionable Service Very poor service indeed....\n",
       "400938    Terrible Experience Waited for 2 hours for my ...\n",
       "400939    Not worth it. Order via deliveroo. Will be my ...\n",
       "400940    A genuine review.. Guys, never ever order onli...\n",
       "Name: full_review, Length: 400941, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['full_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting full_review column to str for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo! disapp...\n",
       "1    Hate to write bad reviews but.... Bad service,...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza. Easy to order a...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: full_review, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['full_review'] = df_reviews['full_review'].astype(str)\n",
    "df_reviews['full_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal\n",
    "##### All the punctuations from the text are removed. string library of Python contains some pre-defined list of punctuations such as ‘!”#$%&'()*+,-./:;?@[\\]^_`{|}~’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>date_of_visit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_of_img_uploaded</th>\n",
       "      <th>full_review</th>\n",
       "      <th>num_of_tokens_title</th>\n",
       "      <th>num_of_tokens_description</th>\n",
       "      <th>num_of_tokens_full_review</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>description_sentiment</th>\n",
       "      <th>full_review_sentiment</th>\n",
       "      <th>review_sentiment_category</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>Actually ordered online with Deliveroo! disapp...</td>\n",
       "      <td>Ordered a chicken Cobb salad which is meant to...</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Actually ordered online with Deliveroo! disapp...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.362500</td>\n",
       "      <td>-0.362500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>Hate to write bad reviews but....</td>\n",
       "      <td>Bad service, bad attitude of owner and average...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hate to write bad reviews but.... Bad service,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Tempting pizzas</td>\n",
       "      <td>I went with a couple a family friend pair who ...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>Quick lunch pizza</td>\n",
       "      <td>Great pizza. Easy to order and delivery was ri...</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quick lunch pizza Great pizza. Easy to order a...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>Nice italian thin crust pizzas</td>\n",
       "      <td>Good for casual dining with friends. Tasty ita...</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating        date                                              title  \\\n",
       "0     3.0  2021-12-04  Actually ordered online with Deliveroo! disapp...   \n",
       "1     1.0  2021-01-26                  Hate to write bad reviews but....   \n",
       "2     4.0  2020-08-21                                    Tempting pizzas   \n",
       "3     5.0  2019-11-09                                  Quick lunch pizza   \n",
       "4     3.0  2019-11-06                     Nice italian thin crust pizzas   \n",
       "\n",
       "                                         description date_of_visit  \\\n",
       "0  Ordered a chicken Cobb salad which is meant to...    2021-12-01   \n",
       "1  Bad service, bad attitude of owner and average...    2021-01-01   \n",
       "2  I went with a couple a family friend pair who ...    2020-03-01   \n",
       "3  Great pizza. Easy to order and delivery was ri...    2019-11-01   \n",
       "4  Good for casual dining with friends. Tasty ita...    2019-10-01   \n",
       "\n",
       "                                                 url  num_of_img_uploaded  \\\n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...                  1.0   \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "\n",
       "                                         full_review  num_of_tokens_title  \\\n",
       "0  Actually ordered online with Deliveroo! disapp...                  6.0   \n",
       "1  Hate to write bad reviews but.... Bad service,...                  6.0   \n",
       "2  Tempting pizzas I went with a couple a family ...                  2.0   \n",
       "3  Quick lunch pizza Great pizza. Easy to order a...                  3.0   \n",
       "4  Nice italian thin crust pizzas Good for casual...                  5.0   \n",
       "\n",
       "   num_of_tokens_description  num_of_tokens_full_review  title_sentiment  \\\n",
       "0                       61.0                       67.0        -0.300000   \n",
       "1                       16.0                       22.0        -0.750000   \n",
       "2                       34.0                       36.0         0.000000   \n",
       "3                       19.0                       22.0         0.333333   \n",
       "4                       21.0                       26.0         0.066667   \n",
       "\n",
       "   description_sentiment  full_review_sentiment  review_sentiment_category  \\\n",
       "0              -0.362500              -0.362500                        0.0   \n",
       "1              -0.130000              -0.130000                        0.0   \n",
       "2               0.566667               0.566667                        1.0   \n",
       "3               0.479762               0.479762                        1.0   \n",
       "4               0.150000               0.150000                        1.0   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  Actually ordered online with Deliveroo disappo...  \n",
       "1  Hate to write bad reviews but Bad service bad ...  \n",
       "2  Tempting pizzas I went with a couple a family ...  \n",
       "3  Quick lunch pizza Great pizza Easy to order an...  \n",
       "4  Nice italian thin crust pizzas Good for casual...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove punctuation\n",
    "def remove_punctuation(review):\n",
    "    review_without_punctuation = \"\".join([i for i in review if i not in string.punctuation])\n",
    "    return review_without_punctuation\n",
    "\n",
    "df_reviews['cleaned_review'] = df_reviews['full_review'].apply(lambda x: remove_punctuation(x))\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing numbers as they do not hold information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo disappo...\n",
       "1    Hate to write bad reviews but Bad service bad ...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza Easy to order an...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['cleaned_review'].replace('\\d', '', regex=True, inplace=True)\n",
    "df_reviews['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing emojis as they do not hold information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo disappo...\n",
       "1    Hate to write bad reviews but Bad service bad ...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza Easy to order an...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emojis(review):\n",
    "    return review.encode('ascii', 'ignore').decode('ascii')\n",
    "df_reviews['cleaned_review'] = df_reviews['cleaned_review'].apply(lambda x: remove_emojis(x))\n",
    "df_reviews['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing nltk english stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service and food is below average Wanted ...</td>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited for  hours for my f...</td>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth it Order via deliveroo Will be my fi...</td>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_review  \\\n",
       "0       Actually ordered online with Deliveroo disappo...   \n",
       "1       Hate to write bad reviews but Bad service bad ...   \n",
       "2       Tempting pizzas I went with a couple a family ...   \n",
       "3       Quick lunch pizza Great pizza Easy to order an...   \n",
       "4       Nice italian thin crust pizzas Good for casual...   \n",
       "...                                                   ...   \n",
       "400936  Poor service and food is below average Wanted ...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited for  hours for my f...   \n",
       "400939  Not worth it Order via deliveroo Will be my fi...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                        cleaned_sw_review  \n",
       "0       Actually ordered online Deliveroo disappointin...  \n",
       "1       Hate write bad reviews Bad service bad attitud...  \n",
       "2       Tempting pizzas I went couple family friend pa...  \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...  \n",
       "4       Nice italian thin crust pizzas Good casual din...  \n",
       "...                                                   ...  \n",
       "400936  Poor service food average Wanted try indian cu...  \n",
       "400937  Questionable Service Very poor service indeed ...  \n",
       "400938  Terrible Experience Waited hours food delivery...  \n",
       "400939  Not worth Order via deliveroo Will first last ...  \n",
       "400940  A genuine review Guys never ever order online ...  \n",
       "\n",
       "[400941 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk library\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# import stopwords fron nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove nltk english stopwords \n",
    "def remove_stopwords(review):\n",
    "    review_words = review.split()\n",
    "    noise_free_words = [word for word in review_words if word not in stopwords]\n",
    "    noise_free_review = \" \".join(noise_free_words)\n",
    "    return noise_free_review\n",
    "\n",
    "df_reviews['cleaned_sw_review'] = df_reviews['cleaned_review'].apply(lambda x: remove_stopwords(x))\n",
    "df_reviews[['cleaned_review', 'cleaned_sw_review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "      <th>cleaned_stem_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service and food is below average Wanted ...</td>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited for  hours for my f...</td>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth it Order via deliveroo Will be my fi...</td>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_review  \\\n",
       "0       Actually ordered online with Deliveroo disappo...   \n",
       "1       Hate to write bad reviews but Bad service bad ...   \n",
       "2       Tempting pizzas I went with a couple a family ...   \n",
       "3       Quick lunch pizza Great pizza Easy to order an...   \n",
       "4       Nice italian thin crust pizzas Good for casual...   \n",
       "...                                                   ...   \n",
       "400936  Poor service and food is below average Wanted ...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited for  hours for my f...   \n",
       "400939  Not worth it Order via deliveroo Will be my fi...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                        cleaned_sw_review  \\\n",
       "0       Actually ordered online Deliveroo disappointin...   \n",
       "1       Hate write bad reviews Bad service bad attitud...   \n",
       "2       Tempting pizzas I went couple family friend pa...   \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...   \n",
       "4       Nice italian thin crust pizzas Good casual din...   \n",
       "...                                                   ...   \n",
       "400936  Poor service food average Wanted try indian cu...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited hours food delivery...   \n",
       "400939  Not worth Order via deliveroo Will first last ...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                      cleaned_stem_review  \n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...  \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...  \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...  \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...  \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...  \n",
       "...                                                   ...  \n",
       "400936  [poor, servic, food, averag, want, tri, indian...  \n",
       "400937  [question, servic, veri, poor, servic, inde, w...  \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...  \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...  \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...  \n",
       "\n",
       "[400941 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string split for Stemming\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_sw_review'].apply(lambda x: x.split())\n",
    "\n",
    "#importing the Stemming function from nltk library\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# function for snowball stemming\n",
    "def snowball_stemming(review):\n",
    "    stem_review = [snowball_stemmer.stem(word) for word in review]\n",
    "    return stem_review\n",
    "\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: snowball_stemming(x))\n",
    "df_reviews[['cleaned_review', 'cleaned_sw_review', 'cleaned_stem_review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "      <th>cleaned_stem_review</th>\n",
       "      <th>cleaned_lem_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_sw_review  \\\n",
       "0       Actually ordered online Deliveroo disappointin...   \n",
       "1       Hate write bad reviews Bad service bad attitud...   \n",
       "2       Tempting pizzas I went couple family friend pa...   \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...   \n",
       "4       Nice italian thin crust pizzas Good casual din...   \n",
       "...                                                   ...   \n",
       "400936  Poor service food average Wanted try indian cu...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited hours food delivery...   \n",
       "400939  Not worth Order via deliveroo Will first last ...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                      cleaned_stem_review  \\\n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...   \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...   \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...   \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...   \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...   \n",
       "...                                                   ...   \n",
       "400936  [poor, servic, food, averag, want, tri, indian...   \n",
       "400937  [question, servic, veri, poor, servic, inde, w...   \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...   \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...   \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...   \n",
       "\n",
       "                                       cleaned_lem_review  \n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...  \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...  \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...  \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...  \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...  \n",
       "...                                                   ...  \n",
       "400936  [poor, servic, food, averag, want, tri, indian...  \n",
       "400937  [question, servic, veri, poor, servic, inde, w...  \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...  \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...  \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...  \n",
       "\n",
       "[400941 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(review):\n",
    "    lemm_review = [wordnet_lemmatizer.lemmatize(word) for word in review]\n",
    "    return lemm_review\n",
    "\n",
    "df_reviews['cleaned_lem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: lemmatizer(x))\n",
    "df_reviews[['cleaned_sw_review', 'cleaned_stem_review', 'cleaned_lem_review']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) \n",
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = df_reviews[df_reviews['review_sentiment_category'].notna()]\n",
    "df_reviews['review_sentiment_category'].astype(int)\n",
    "df_reviews['rating'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def nb_tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    predictions = nb.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, nb.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # for i, j in enumerate(nb.classes_):\n",
    "    #     coefficients = nb.coef_[i]\n",
    "    #     weights = list(zip(vect.get_feature_names(), coefficients))\n",
    "    #     print('Most Positive Coefficients:')\n",
    "    #     print(sorted(weights,key=lambda x: -x[1])[:10])\n",
    "    #     print('Most Negative Coefficients:')\n",
    "    #     print(sorted(weights,key=lambda x: x[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8949125804359754\n",
      "Accuracy:  0.887427046440864\n",
      "Precision:  0.8845227665757122\n",
      "Recall:  0.887427046440864\n",
      "Confusion Matrix:  [[ 6796  4892]\n",
      " [ 4135 64365]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "nb_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8571357310320746\n",
      "Accuracy:  0.8548910061355813\n",
      "Precision:  0.8662743849876113\n",
      "Recall:  0.8548910061355813\n",
      "Confusion Matrix:  [[   56 11632]\n",
      " [    4 68496]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "nb_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_sw_review (cleaned reviews that have stop words removed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_sw_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8972352471691525\n",
      "Accuracy:  0.8896842420312266\n",
      "Precision:  0.8851804595107275\n",
      "Recall:  0.8896842420312266\n",
      "Confusion Matrix:  [[ 6646  5042]\n",
      " [ 3804 64696]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "nb_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8590250411532898\n",
      "Accuracy:  0.8555768942983988\n",
      "Precision:  0.8660365119898119\n",
      "Recall:  0.8555768942983988\n",
      "Confusion Matrix:  [[  116 11572]\n",
      " [    9 68491]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "nb_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_stem_review (cleaned reviews that have stop words removed and stemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing step to convert list column into text column\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: ' '.join(x) )\n",
    "\n",
    "\n",
    "# define X and y\n",
    "X = df_reviews['cleaned_stem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8955704095375867\n",
      "Accuracy:  0.8891729435825809\n",
      "Precision:  0.8847818500317601\n",
      "Recall:  0.8891729435825809\n",
      "Confusion Matrix:  [[ 6646  5042]\n",
      " [ 3845 64655]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "nb_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8587413328677608\n",
      "Accuracy:  0.8554771287474435\n",
      "Precision:  0.8642170933226381\n",
      "Recall:  0.8554771287474435\n",
      "Confusion Matrix:  [[  109 11579]\n",
      " [   10 68490]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "nb_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_lem_review (cleaned reviews that have stop words removed, stemmatized and lemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing step to convert list column into text column\n",
    "df_reviews['cleaned_lem_review'] = df_reviews['cleaned_lem_review'].apply(lambda x: ' '.join(x) )\n",
    "\n",
    "\n",
    "# define X and y\n",
    "X = df_reviews['cleaned_lem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8956047039457276\n",
      "Accuracy:  0.8892228263580586\n",
      "Precision:  0.8848612429639288\n",
      "Recall:  0.8892228263580586\n",
      "Confusion Matrix:  [[ 6652  5036]\n",
      " [ 3847 64653]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "nb_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8588255100513793\n",
      "Accuracy:  0.8555145408290518\n",
      "Precision:  0.8645456655747108\n",
      "Recall:  0.8555145408290518\n",
      "Confusion Matrix:  [[  112 11576]\n",
      " [   10 68490]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "nb_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) \n",
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def lr_tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    lr = LogisticRegression(max_iter=3000)\n",
    "    lr.fit(X_train_dtm, y_train)\n",
    "    predictions = lr.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, lr.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9654873547164164\n",
      "Accuracy:  0.9350526263281289\n",
      "Precision:  0.9331026114692008\n",
      "Recall:  0.9350526263281289\n",
      "Confusion Matrix:  [[ 8566  3122]\n",
      " [ 2086 66414]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "lr_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9452723599541079\n",
      "Accuracy:  0.9342046191450092\n",
      "Precision:  0.9312205653307022\n",
      "Recall:  0.9342046191450092\n",
      "Confusion Matrix:  [[ 7976  3712]\n",
      " [ 1564 66936]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "lr_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_sw_review (cleaned reviews that have stop words removed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_sw_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9622605626777074\n",
      "Accuracy:  0.9307751783309224\n",
      "Precision:  0.9283363743881674\n",
      "Recall:  0.9307751783309224\n",
      "Confusion Matrix:  [[ 8292  3396]\n",
      " [ 2155 66345]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "lr_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9419177433032374\n",
      "Accuracy:  0.9304384695964484\n",
      "Precision:  0.926998546769406\n",
      "Recall:  0.9304384695964484\n",
      "Confusion Matrix:  [[ 7689  3999]\n",
      " [ 1579 66921]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "lr_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_stem_review (cleaned reviews that have stop words removed and stemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_stem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.954606674315359\n",
      "Accuracy:  0.9270713822517085\n",
      "Precision:  0.924116727646855\n",
      "Recall:  0.9270713822517085\n",
      "Confusion Matrix:  [[ 8034  3654]\n",
      " [ 2194 66306]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "lr_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9377275901631167\n",
      "Accuracy:  0.9278196238838728\n",
      "Precision:  0.9240977259102136\n",
      "Recall:  0.9278196238838728\n",
      "Confusion Matrix:  [[ 7606  4082]\n",
      " [ 1706 66794]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "lr_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_lem_review (cleaned reviews that have stop words removed, stemmatized and lemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_lem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9544694966827955\n",
      "Accuracy:  0.9271087943333167\n",
      "Precision:  0.9241411084231149\n",
      "Recall:  0.9271087943333167\n",
      "Confusion Matrix:  [[ 8030  3658]\n",
      " [ 2187 66313]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "lr_tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9376932957549758\n",
      "Accuracy:  0.9279318601286975\n",
      "Precision:  0.9242265066752277\n",
      "Recall:  0.9279318601286975\n",
      "Confusion Matrix:  [[ 7616  4072]\n",
      " [ 1707 66793]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "lr_tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) \n",
    "#### Random Forest, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    randomforest = RandomForestClassifier(n_estimators=101, criterion='entropy')\n",
    "    randomforest.fit(X_train_dtm, y_train)\n",
    "    predictions = randomforest.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, randomforest.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9999875293061306\n",
      "Accuracy:  0.868733476330623\n",
      "Precision:  0.8771579803819611\n",
      "Recall:  0.868733476330623\n",
      "Confusion Matrix:  [[ 1252 10436]\n",
      " [   90 68410]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9999875293061306\n",
      "Accuracy:  0.8677607622088093\n",
      "Precision:  0.8771270214770107\n",
      "Recall:  0.8677607622088093\n",
      "Confusion Matrix:  [[ 1160 10528]\n",
      " [   76 68424]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
