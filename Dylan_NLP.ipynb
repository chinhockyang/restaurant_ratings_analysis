{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('final_restaurant_review_data.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Actually ordered online with Deliveroo! disapp...\n",
       "1         Hate to write bad reviews but.... Bad service,...\n",
       "2         Tempting pizzas I went with a couple a family ...\n",
       "3         Quick lunch pizza Great pizza. Easy to order a...\n",
       "4         Nice italian thin crust pizzas Good for casual...\n",
       "                                ...                        \n",
       "400936    Poor service and food is below average. Wanted...\n",
       "400937    Questionable Service Very poor service indeed....\n",
       "400938    Terrible Experience Waited for 2 hours for my ...\n",
       "400939    Not worth it. Order via deliveroo. Will be my ...\n",
       "400940    A genuine review.. Guys, never ever order onli...\n",
       "Name: full_review, Length: 400941, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['full_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting full_review column to str for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo! disapp...\n",
       "1    Hate to write bad reviews but.... Bad service,...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza. Easy to order a...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: full_review, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['full_review'] = df_reviews['full_review'].astype(str)\n",
    "df_reviews['full_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal\n",
    "##### All the punctuations from the text are removed. string library of Python contains some pre-defined list of punctuations such as ‘!”#$%&'()*+,-./:;?@[\\]^_`{|}~’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>date_of_visit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_of_img_uploaded</th>\n",
       "      <th>full_review</th>\n",
       "      <th>num_of_tokens_title</th>\n",
       "      <th>num_of_tokens_description</th>\n",
       "      <th>num_of_tokens_full_review</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>description_sentiment</th>\n",
       "      <th>full_review_sentiment</th>\n",
       "      <th>review_sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>Actually ordered online with Deliveroo! disapp...</td>\n",
       "      <td>Ordered a chicken Cobb salad which is meant to...</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.362500</td>\n",
       "      <td>-0.362500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>Hate to write bad reviews but....</td>\n",
       "      <td>Bad service, bad attitude of owner and average...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Tempting pizzas</td>\n",
       "      <td>I went with a couple a family friend pair who ...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>Quick lunch pizza</td>\n",
       "      <td>Great pizza. Easy to order and delivery was ri...</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>Nice italian thin crust pizzas</td>\n",
       "      <td>Good for casual dining with friends. Tasty ita...</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating        date                                              title  \\\n",
       "0     3.0  2021-12-04  Actually ordered online with Deliveroo! disapp...   \n",
       "1     1.0  2021-01-26                  Hate to write bad reviews but....   \n",
       "2     4.0  2020-08-21                                    Tempting pizzas   \n",
       "3     5.0  2019-11-09                                  Quick lunch pizza   \n",
       "4     3.0  2019-11-06                     Nice italian thin crust pizzas   \n",
       "\n",
       "                                         description date_of_visit  \\\n",
       "0  Ordered a chicken Cobb salad which is meant to...    2021-12-01   \n",
       "1  Bad service, bad attitude of owner and average...    2021-01-01   \n",
       "2  I went with a couple a family friend pair who ...    2020-03-01   \n",
       "3  Great pizza. Easy to order and delivery was ri...    2019-11-01   \n",
       "4  Good for casual dining with friends. Tasty ita...    2019-10-01   \n",
       "\n",
       "                                                 url  num_of_img_uploaded  \\\n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...                  1.0   \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...                  0.0   \n",
       "\n",
       "                                         full_review  num_of_tokens_title  \\\n",
       "0  Actually ordered online with Deliveroo disappo...                  6.0   \n",
       "1  Hate to write bad reviews but Bad service bad ...                  6.0   \n",
       "2  Tempting pizzas I went with a couple a family ...                  2.0   \n",
       "3  Quick lunch pizza Great pizza Easy to order an...                  3.0   \n",
       "4  Nice italian thin crust pizzas Good for casual...                  5.0   \n",
       "\n",
       "   num_of_tokens_description  num_of_tokens_full_review  title_sentiment  \\\n",
       "0                       61.0                       67.0        -0.300000   \n",
       "1                       16.0                       22.0        -0.750000   \n",
       "2                       34.0                       36.0         0.000000   \n",
       "3                       19.0                       22.0         0.333333   \n",
       "4                       21.0                       26.0         0.066667   \n",
       "\n",
       "   description_sentiment  full_review_sentiment  review_sentiment_category  \n",
       "0              -0.362500              -0.362500                        0.0  \n",
       "1              -0.130000              -0.130000                        0.0  \n",
       "2               0.566667               0.566667                        1.0  \n",
       "3               0.479762               0.479762                        1.0  \n",
       "4               0.150000               0.150000                        1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove punctuation\n",
    "def remove_punctuation(review):\n",
    "    review_without_punctuation = \"\".join([i for i in review if i not in string.punctuation])\n",
    "    return review_without_punctuation\n",
    "\n",
    "df_reviews['cleaned_review'] = df_reviews['full_review'].apply(lambda x: remove_punctuation(x))\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or we can remove punctuations manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo disappo...\n",
       "1    Hate to write bad reviews but Bad service bad ...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza Easy to order an...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['cleaned_review'] = df_reviews['full_review'].apply(lambda x: ' '.join(re.sub(\"[.,!?:;-='...@#_]\", \" \", x).split()))\n",
    "df_reviews['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing numbers as they do not hold information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo disappo...\n",
       "1    Hate to write bad reviews but Bad service bad ...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza Easy to order an...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['cleaned_review'].replace('\\d', '', regex=True, inplace=True)\n",
    "df_reviews['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing emojis as they do not hold information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Actually ordered online with Deliveroo disappo...\n",
       "1    Hate to write bad reviews but Bad service bad ...\n",
       "2    Tempting pizzas I went with a couple a family ...\n",
       "3    Quick lunch pizza Great pizza Easy to order an...\n",
       "4    Nice italian thin crust pizzas Good for casual...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emojis(review):\n",
    "    return review.encode('ascii', 'ignore').decode('ascii')\n",
    "df_reviews['cleaned_review'] = df_reviews['cleaned_review'].apply(lambda x: remove_emojis(x))\n",
    "df_reviews['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing nltk english stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service and food is below average Wanted ...</td>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited for  hours for my f...</td>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth it Order via deliveroo Will be my fi...</td>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_review  \\\n",
       "0       Actually ordered online with Deliveroo disappo...   \n",
       "1       Hate to write bad reviews but Bad service bad ...   \n",
       "2       Tempting pizzas I went with a couple a family ...   \n",
       "3       Quick lunch pizza Great pizza Easy to order an...   \n",
       "4       Nice italian thin crust pizzas Good for casual...   \n",
       "...                                                   ...   \n",
       "400936  Poor service and food is below average Wanted ...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited for  hours for my f...   \n",
       "400939  Not worth it Order via deliveroo Will be my fi...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                        cleaned_sw_review  \n",
       "0       Actually ordered online Deliveroo disappointin...  \n",
       "1       Hate write bad reviews Bad service bad attitud...  \n",
       "2       Tempting pizzas I went couple family friend pa...  \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...  \n",
       "4       Nice italian thin crust pizzas Good casual din...  \n",
       "...                                                   ...  \n",
       "400936  Poor service food average Wanted try indian cu...  \n",
       "400937  Questionable Service Very poor service indeed ...  \n",
       "400938  Terrible Experience Waited hours food delivery...  \n",
       "400939  Not worth Order via deliveroo Will first last ...  \n",
       "400940  A genuine review Guys never ever order online ...  \n",
       "\n",
       "[400941 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk library\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# import stopwords fron nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove nltk english stopwords \n",
    "def remove_stopwords(review):\n",
    "    review_words = review.split()\n",
    "    noise_free_words = [word for word in review_words if word not in stopwords]\n",
    "    noise_free_review = \" \".join(noise_free_words)\n",
    "    return noise_free_review\n",
    "\n",
    "df_reviews['cleaned_sw_review'] = df_reviews['cleaned_review'].apply(lambda x: remove_stopwords(x))\n",
    "df_reviews[['cleaned_review', 'cleaned_sw_review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "      <th>cleaned_stem_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online with Deliveroo disappo...</td>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate to write bad reviews but Bad service bad ...</td>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went with a couple a family ...</td>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy to order an...</td>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good for casual...</td>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service and food is below average Wanted ...</td>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited for  hours for my f...</td>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth it Order via deliveroo Will be my fi...</td>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_review  \\\n",
       "0       Actually ordered online with Deliveroo disappo...   \n",
       "1       Hate to write bad reviews but Bad service bad ...   \n",
       "2       Tempting pizzas I went with a couple a family ...   \n",
       "3       Quick lunch pizza Great pizza Easy to order an...   \n",
       "4       Nice italian thin crust pizzas Good for casual...   \n",
       "...                                                   ...   \n",
       "400936  Poor service and food is below average Wanted ...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited for  hours for my f...   \n",
       "400939  Not worth it Order via deliveroo Will be my fi...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                        cleaned_sw_review  \\\n",
       "0       Actually ordered online Deliveroo disappointin...   \n",
       "1       Hate write bad reviews Bad service bad attitud...   \n",
       "2       Tempting pizzas I went couple family friend pa...   \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...   \n",
       "4       Nice italian thin crust pizzas Good casual din...   \n",
       "...                                                   ...   \n",
       "400936  Poor service food average Wanted try indian cu...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited hours food delivery...   \n",
       "400939  Not worth Order via deliveroo Will first last ...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                      cleaned_stem_review  \n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...  \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...  \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...  \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...  \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...  \n",
       "...                                                   ...  \n",
       "400936  [poor, servic, food, averag, want, tri, indian...  \n",
       "400937  [question, servic, veri, poor, servic, inde, w...  \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...  \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...  \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...  \n",
       "\n",
       "[400941 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string split for Stemming\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_sw_review'].apply(lambda x: x.split())\n",
    "\n",
    "#importing the Stemming function from nltk library\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# function for snowball stemming\n",
    "def snowball_stemming(review):\n",
    "    stem_review = [snowball_stemmer.stem(word) for word in review]\n",
    "    return stem_review\n",
    "\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: snowball_stemming(x))\n",
    "df_reviews[['cleaned_review', 'cleaned_sw_review', 'cleaned_stem_review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_sw_review</th>\n",
       "      <th>cleaned_stem_review</th>\n",
       "      <th>cleaned_lem_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actually ordered online Deliveroo disappointin...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "      <td>[actual, order, onlin, deliveroo, disappoint, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate write bad reviews Bad service bad attitud...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "      <td>[hate, write, bad, review, bad, servic, bad, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempting pizzas I went couple family friend pa...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "      <td>[tempt, pizza, i, went, coupl, famili, friend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quick lunch pizza Great pizza Easy order deliv...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "      <td>[quick, lunch, pizza, great, pizza, easi, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice italian thin crust pizzas Good casual din...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "      <td>[nice, italian, thin, crust, pizza, good, casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400936</th>\n",
       "      <td>Poor service food average Wanted try indian cu...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "      <td>[poor, servic, food, averag, want, tri, indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400937</th>\n",
       "      <td>Questionable Service Very poor service indeed ...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "      <td>[question, servic, veri, poor, servic, inde, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400938</th>\n",
       "      <td>Terrible Experience Waited hours food delivery...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "      <td>[terribl, experi, wait, hour, food, deliveri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400939</th>\n",
       "      <td>Not worth Order via deliveroo Will first last ...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "      <td>[not, worth, order, via, deliveroo, will, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400940</th>\n",
       "      <td>A genuine review Guys never ever order online ...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "      <td>[a, genuin, review, guy, never, ever, order, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_sw_review  \\\n",
       "0       Actually ordered online Deliveroo disappointin...   \n",
       "1       Hate write bad reviews Bad service bad attitud...   \n",
       "2       Tempting pizzas I went couple family friend pa...   \n",
       "3       Quick lunch pizza Great pizza Easy order deliv...   \n",
       "4       Nice italian thin crust pizzas Good casual din...   \n",
       "...                                                   ...   \n",
       "400936  Poor service food average Wanted try indian cu...   \n",
       "400937  Questionable Service Very poor service indeed ...   \n",
       "400938  Terrible Experience Waited hours food delivery...   \n",
       "400939  Not worth Order via deliveroo Will first last ...   \n",
       "400940  A genuine review Guys never ever order online ...   \n",
       "\n",
       "                                      cleaned_stem_review  \\\n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...   \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...   \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...   \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...   \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...   \n",
       "...                                                   ...   \n",
       "400936  [poor, servic, food, averag, want, tri, indian...   \n",
       "400937  [question, servic, veri, poor, servic, inde, w...   \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...   \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...   \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...   \n",
       "\n",
       "                                       cleaned_lem_review  \n",
       "0       [actual, order, onlin, deliveroo, disappoint, ...  \n",
       "1       [hate, write, bad, review, bad, servic, bad, a...  \n",
       "2       [tempt, pizza, i, went, coupl, famili, friend,...  \n",
       "3       [quick, lunch, pizza, great, pizza, easi, orde...  \n",
       "4       [nice, italian, thin, crust, pizza, good, casu...  \n",
       "...                                                   ...  \n",
       "400936  [poor, servic, food, averag, want, tri, indian...  \n",
       "400937  [question, servic, veri, poor, servic, inde, w...  \n",
       "400938  [terribl, experi, wait, hour, food, deliveri, ...  \n",
       "400939  [not, worth, order, via, deliveroo, will, firs...  \n",
       "400940  [a, genuin, review, guy, never, ever, order, o...  \n",
       "\n",
       "[400941 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(review):\n",
    "    lemm_review = [wordnet_lemmatizer.lemmatize(word) for word in review]\n",
    "    return lemm_review\n",
    "\n",
    "df_reviews['cleaned_lem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: lemmatizer(x))\n",
    "df_reviews[['cleaned_sw_review', 'cleaned_stem_review', 'cleaned_lem_review']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) \n",
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = df_reviews[df_reviews['review_sentiment_category'].notna()]\n",
    "df_reviews['review_sentiment_category'].astype(int)\n",
    "df_reviews['rating'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    predictions = nb.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, nb.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # for i, j in enumerate(nb.classes_):\n",
    "    #     coefficients = nb.coef_[i]\n",
    "    #     weights = list(zip(vect.get_feature_names(), coefficients))\n",
    "    #     print('Most Positive Coefficients:')\n",
    "    #     print(sorted(weights,key=lambda x: -x[1])[:10])\n",
    "    #     print('Most Negative Coefficients:')\n",
    "    #     print(sorted(weights,key=lambda x: x[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8831464807701901\n",
      "Accuracy:  0.8785479124058463\n",
      "Precision:  0.8845469561226508\n",
      "Recall:  0.8785479124058463\n",
      "Confusion Matrix:  [[ 7482  4206]\n",
      " [ 5533 62967]]\n",
      "Most Positive Coefficients:\n",
      "[('the', -2.87193141332296), ('and', -3.245440193787214), ('to', -3.836335628181656), ('was', -3.9601327336590533), ('of', -4.119155989391038), ('is', -4.1524402829814555), ('for', -4.189394082620948), ('food', -4.194227862354735), ('we', -4.4132936243422325), ('good', -4.4911345315831035)]\n",
      "Most Negative Coefficients:\n",
      "[('aaaaahhh', -16.673068161259952), ('aaaarrgghhh', -16.673068161259952), ('aaargh', -16.673068161259952), ('aaid', -16.673068161259952), ('aain', -16.673068161259952), ('aalloo', -16.673068161259952), ('aamchi', -16.673068161259952), ('aampapad', -16.673068161259952), ('aarea', -16.673068161259952), ('aasis', -16.673068161259952)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jl/hld_bmy11gz826x_7rs4b08m0000gn/T/ipykernel_7730/3762429850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcountvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenize_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountvect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jl/hld_bmy11gz826x_7rs4b08m0000gn/T/ipykernel_7730/671646941.py\u001b[0m in \u001b[0;36mtokenize_test\u001b[0;34m(vect, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Most Positive Coefficients:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8831464807701901\n",
      "Accuracy:  0.8785479124058463\n",
      "Precision:  0.8845469561226508\n",
      "Recall:  0.8785479124058463\n",
      "Confusion Matrix:  [[ 7482  4206]\n",
      " [ 5533 62967]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8659805706589515\n",
      "Accuracy:  0.8622736569062702\n",
      "Precision:  0.867377302181875\n",
      "Recall:  0.8622736569062702\n",
      "Confusion Matrix:  [[  725 10963]\n",
      " [   81 68419]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_sw_review (cleaned reviews that have stop words removed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_sw_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.886363919788497\n",
      "Accuracy:  0.8810420511797277\n",
      "Precision:  0.8850284259871829\n",
      "Recall:  0.8810420511797277\n",
      "Confusion Matrix:  [[ 7374  4314]\n",
      " [ 5225 63275]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.869734249513643\n",
      "Accuracy:  0.8650047388636704\n",
      "Precision:  0.8667622785006162\n",
      "Recall:  0.8650047388636704\n",
      "Confusion Matrix:  [[ 1002 10686]\n",
      " [  139 68361]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_stem_review (cleaned reviews that have stop words removed and stemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing step to convert list column into text column\n",
    "df_reviews['cleaned_stem_review'] = df_reviews['cleaned_stem_review'].apply(lambda x: ' '.join(x) )\n",
    "\n",
    "\n",
    "# define X and y\n",
    "X = df_reviews['cleaned_stem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8848237890956253\n",
      "Accuracy:  0.8801815733027386\n",
      "Precision:  0.8847095531969069\n",
      "Recall:  0.8801815733027386\n",
      "Confusion Matrix:  [[ 7396  4292]\n",
      " [ 5316 63184]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8686337107796678\n",
      "Accuracy:  0.8642315558437671\n",
      "Precision:  0.8673913957620113\n",
      "Recall:  0.8642315558437671\n",
      "Confusion Matrix:  [[  917 10771]\n",
      " [  116 68384]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_lem_review (cleaned reviews that have stop words removed, stemmatized and lemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing step to convert list column into text column\n",
    "df_reviews['cleaned_lem_review'] = df_reviews['cleaned_lem_review'].apply(lambda x: ' '.join(x) )\n",
    "\n",
    "\n",
    "# define X and y\n",
    "X = df_reviews['cleaned_lem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8847084351773332\n",
      "Accuracy:  0.8801691026088692\n",
      "Precision:  0.8847387856390609\n",
      "Recall:  0.8801691026088692\n",
      "Confusion Matrix:  [[ 7400  4288]\n",
      " [ 5321 63179]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8687615353918292\n",
      "Accuracy:  0.8643562627824612\n",
      "Precision:  0.8671427114871177\n",
      "Recall:  0.8643562627824612\n",
      "Confusion Matrix:  [[  932 10756]\n",
      " [  121 68379]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) \n",
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    lr = LogisticRegression(max_iter=3000)\n",
    "    lr.fit(X_train_dtm, y_train)\n",
    "    predictions = lr.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, lr.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9582979997007034\n",
      "Accuracy:  0.932171896044296\n",
      "Precision:  0.9299158669542914\n",
      "Recall:  0.932171896044296\n",
      "Confusion Matrix:  [[ 8388  3300]\n",
      " [ 2139 66361]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9419083902828354\n",
      "Accuracy:  0.9320970718810795\n",
      "Precision:  0.9288691646671952\n",
      "Recall:  0.9320970718810795\n",
      "Confusion Matrix:  [[ 7832  3856]\n",
      " [ 1589 66911]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_sw_review (cleaned reviews that have stop words removed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_sw_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.955077443008929\n",
      "Accuracy:  0.9275203272310071\n",
      "Precision:  0.9247740596181879\n",
      "Recall:  0.9275203272310071\n",
      "Confusion Matrix:  [[ 8115  3573]\n",
      " [ 2239 66261]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9389996009377962\n",
      "Accuracy:  0.9290292811892054\n",
      "Precision:  0.9254245403061127\n",
      "Recall:  0.9290292811892054\n",
      "Confusion Matrix:  [[ 7622  4066]\n",
      " [ 1625 66875]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_stem_review (cleaned reviews that have stop words removed and stemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_stem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9470961989325086\n",
      "Accuracy:  0.9249014815184317\n",
      "Precision:  0.9216687702434239\n",
      "Recall:  0.9249014815184317\n",
      "Confusion Matrix:  [[ 7897  3791]\n",
      " [ 2231 66269]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9349216840425001\n",
      "Accuracy:  0.9261859629869806\n",
      "Precision:  0.922276077518517\n",
      "Recall:  0.9261859629869806\n",
      "Confusion Matrix:  [[ 7533  4155]\n",
      " [ 1764 66736]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_lem_review (cleaned reviews that have stop words removed, stemmatized and lemmatized)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_lem_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9469746096672819\n",
      "Accuracy:  0.9249264229061706\n",
      "Precision:  0.9216729183282276\n",
      "Recall:  0.9249264229061706\n",
      "Confusion Matrix:  [[ 7890  3798]\n",
      " [ 2222 66278]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9348686835935551\n",
      "Accuracy:  0.92619843368085\n",
      "Precision:  0.9222940738422084\n",
      "Recall:  0.92619843368085\n",
      "Confusion Matrix:  [[ 7538  4150]\n",
      " [ 1768 66732]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) \n",
    "#### Random Forest, using CountVectorizer and TFIDVectorizer\n",
    "#### Model Training & Prediction on cleaned_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df_reviews['cleaned_review']\n",
    "y = df_reviews['review_sentiment_category']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the review_sentiment_category\n",
    "    randomforest = RandomForestClassifier(n_estimators=101, criterion='entropy')\n",
    "    randomforest.fit(X_train_dtm, y_train)\n",
    "    predictions = randomforest.predict(X_test_dtm)\n",
    "    \n",
    "    # print the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, randomforest.predict(X_train_dtm)))\n",
    "\n",
    "    # print the accuracy of its predictions\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    # print the precision of the model\n",
    "    print('Precision: ', precision_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print the recall of the model\n",
    "    print('Recall: ', recall_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print('Confusion Matrix: ', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9999875293061306\n",
      "Accuracy:  0.868733476330623\n",
      "Precision:  0.8771579803819611\n",
      "Recall:  0.868733476330623\n",
      "Confusion Matrix:  [[ 1252 10436]\n",
      " [   90 68410]]\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "tokenize_test(countvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9999875293061306\n",
      "Accuracy:  0.8677607622088093\n",
      "Precision:  0.8771270214770107\n",
      "Recall:  0.8677607622088093\n",
      "Confusion Matrix:  [[ 1160 10528]\n",
      " [   76 68424]]\n"
     ]
    }
   ],
   "source": [
    "tfidvect = TfidfVectorizer()\n",
    "tokenize_test(tfidvect, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
